

<!DOCTYPE html>
<html class="writer-html5" lang="en-EN" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>5.17.3. sail.EngineImagePreProcess &mdash; SOPHON-SAIL 3.10.2
 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=01d1187f"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.17.4.1. sail.algo_yolov5_post_1output" href="sail.algo_yolov5_post_1output.html" />
    <link rel="prev" title="5.17.2. sail.ImagePreProcess" href="sail.ImagePreProcess.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            SOPHON-SAIL
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Catalog</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../1_disclaimer.html">1. Disclaimer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../2_sail.html">2. SAIL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../3_build.html">3. Compilation and Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../4_module_cpp.html">4. SAIL C++ API</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../5_module_python.html">5. SAIL Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../Basicfunction.html">5.1. Basic function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../0_enum_type/enum_index.html">5.2. SAIL enum type</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.Handle.html">5.3. sail.Handle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.Tensor.html">5.4. sail.Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.PaddingAtrr.html">5.5. sail.PaddingAtrr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.Engine.html">5.6. sail.Engine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.MultiEngine.html">5.7. sail.MultiEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.bm_image.html">5.8. sail.bm_image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.BMImage.html">5.9. sail.BMImage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.BMImageArray.html">5.10. sail.BMImageArray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.Decoder.html">5.11. sail.Decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.Encoder.html">5.12. sail.Encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.Decoder_RawStream.html">5.13. sail.Decoder_RawStream</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.Bmcv.html">5.14. sail.Bmcv</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.Blend.html">5.15. sail.Blend</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sail.MultiDecoder.html">5.16. sail.MultiDecoder</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="high_perform_index.html">5.17. SAIL Python high performance interface</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="sail.TensorPTRWithName.html">5.17.1. sail.TensorPTRWithName</a></li>
<li class="toctree-l3"><a class="reference internal" href="sail.ImagePreProcess.html">5.17.2. sail.ImagePreProcess</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">5.17.3. sail.EngineImagePreProcess</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#init">5.17.3.1. __init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="#initimagepreprocess">5.17.3.2. InitImagePreProcess</a></li>
<li class="toctree-l4"><a class="reference internal" href="#setpaddingatrr">5.17.3.3. SetPaddingAtrr</a></li>
<li class="toctree-l4"><a class="reference internal" href="#setconvertatrr">5.17.3.4. SetConvertAtrr</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pushimage">5.17.3.5. PushImage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getbatchdata-npy">5.17.3.6. GetBatchData_Npy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getbatchdata-npy2">5.17.3.7. GetBatchData_Npy2</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getbatchdata">5.17.3.8. GetBatchData</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-graph-name">5.17.3.9. get_graph_name</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-width">5.17.3.10. get_input_width</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-height">5.17.3.11. get_input_height</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-names">5.17.3.12. get_output_names</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-shape">5.17.3.13. get_output_shape</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#yolov5-post-processing-acceleration-interfaces">5.17.4. Yolov5 post-processing acceleration interfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#yolox-post-processing-acceleration-interfaces">5.17.5. Yolox post-processing acceleration interfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#yolov8-post-processing-acceleration-interfaces">5.17.6. Yolov8 post-processing acceleration interfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#sort">5.17.7. sort</a></li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#deepsort">5.17.8. deepsort</a></li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#bytetrack">5.17.9. bytetrack</a></li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#openpose">5.17.10. openpose</a></li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#nms-rotated">5.17.11. nms_rotated</a></li>
<li class="toctree-l3"><a class="reference internal" href="high_perform_index.html#yolov8-seg-tpu-post-processing-acceleration-interfaces">5.17.12. Yolov8_seg TPU post-processing acceleration interfaces</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../6_appendix.html">6. Appendix</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">SOPHON-SAIL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../5_module_python.html"><span class="section-number">5. </span>SAIL Python API</a></li>
          <li class="breadcrumb-item"><a href="high_perform_index.html"><span class="section-number">5.17. </span>SAIL Python high performance interface</a></li>
      <li class="breadcrumb-item active"><span class="section-number">5.17.3. </span>sail.EngineImagePreProcess</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/module_python/1_high_perform_interface/sail.EngineImagePreProcess.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sail-engineimagepreprocess">
<h1><span class="section-number">5.17.3. </span>sail.EngineImagePreProcess<a class="headerlink" href="#sail-engineimagepreprocess" title="Link to this heading"></a></h1>
<p>Image inference interface with preprocessing function, internal use of thread pool way, higher efficiency while using Python.</p>
<section id="init">
<h2><span class="section-number">5.17.3.1. </span>__init__<a class="headerlink" href="#init" title="Link to this heading"></a></h2>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">bmodel_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">tpu_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">use_mat_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">core_list</span><span class="p">:</span><span class="nb">list</span> <span class="o">=</span> <span class="p">[])</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p>bmodel_path: str</p></li>
</ul>
<p>The path of the input model.</p>
<ul class="simple">
<li><p>tpu_id: int</p></li>
</ul>
<p>The Tensor Computing Processor id that used.</p>
<ul class="simple">
<li><p>use_mat_output: bool</p></li>
</ul>
<p>Whether to use OpenCV’s Mat as the output of the picture. The default value is False, which means not used.</p>
<ul class="simple">
<li><p>use_mat_output: bool</p></li>
</ul>
<p>When using the processor and BModel that support multi-core inference, you can choose multiple cores to use for inference.
By default, N cores starting from core0 are used for inference, and N is determined by the current bmodel.
For processors and bmodel models that only support single-core inference, only a single core used for inference is supported,
and the input list length of the parameter must be 1, if the length of the incoming list is greater than 1, the inference will be automatically on the core0.
Default is empty. If this parameter is not specified, the inference is performed by N cores starting from core 0.</p>
</section>
<section id="initimagepreprocess">
<h2><span class="section-number">5.17.3.2. </span>InitImagePreProcess<a class="headerlink" href="#initimagepreprocess" title="Link to this heading"></a></h2>
<p>Initialize the image preprocessing module.</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">InitImagePreProcess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">resize_mode</span><span class="p">:</span> <span class="n">sail_resize_type</span><span class="p">,</span>
            <span class="n">bgr2rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">queue_in_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
            <span class="n">queue_out_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p>resize_mode: sail_resize_type</p></li>
</ul>
<p>Methods of internal scaling.</p>
<ul class="simple">
<li><p>bgr2rgb: bool</p></li>
</ul>
<p>Whether to convert an image from BGR to RGB.</p>
<ul class="simple">
<li><p>queue_in_size: int</p></li>
</ul>
<p>The maximum length of the input image queue cache, which defaults to 20.
Must not be less than the batch_size of bmodel, if not, the value will be set to batch_size.</p>
<ul class="simple">
<li><p>queue_out_size: int</p></li>
</ul>
<p>The maximum length of Tensor queue cache of preprocess result, which is 20 by default.
Must not be less than the batch_size of bmodel, if not, the value will be set to batch_size.</p>
<p><strong>Returns:</strong></p>
<p>Return 0 on success and other values on failure.</p>
</section>
<section id="setpaddingatrr">
<h2><span class="section-number">5.17.3.3. </span>SetPaddingAtrr<a class="headerlink" href="#setpaddingatrr" title="Link to this heading"></a></h2>
<p>Sets the Padding properties, only works when the resize_mode is among BM_PADDING_VPP_NEAREST, BM_PADDING_TPU_NEAREST, BM_PADDING_TPU_LINEAR, BM_PADDING_TPU_BICUBIC.</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">SetPaddingAtrr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">padding_b</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">114</span><span class="p">,</span>
            <span class="n">padding_g</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">114</span><span class="p">,</span>
            <span class="n">padding_r</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">114</span><span class="p">,</span>
            <span class="n">align</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Parameters:</strong>
* padding_b: int</p>
<p>The padding pixel value of b channel, which defaults to 114.</p>
<ul class="simple">
<li><p>padding_g: int</p></li>
</ul>
<p>The padding pixel value of g channel, which defaults to 114.</p>
<ul class="simple">
<li><p>padding_r: int</p></li>
</ul>
<p>The padding pixel value of r channel, which defaults to 114.</p>
<ul class="simple">
<li><p>align: int</p></li>
</ul>
<p>Image fill position, 0 indicates fill from the top left corner, 1 indicates center fill, default is 0.</p>
<p><strong>Returns:</strong></p>
<p>Return 0 on success and other values on failure.</p>
</section>
<section id="setconvertatrr">
<h2><span class="section-number">5.17.3.4. </span>SetConvertAtrr<a class="headerlink" href="#setconvertatrr" title="Link to this heading"></a></h2>
<p>Sets the properties of the linear transformation.</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">SetConvertAtrr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha_beta</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Parameters:</strong></p>
<ul>
<li><p>alpha_beta: (a0, b0), (a1, b1), (a2, b2)。</p>
<blockquote>
<div><p>a0 is the coefficient of linear transformation for the 0th channel;</p>
<p>b0 is the offset of linear transformation for the 0th channel;</p>
<p>a1 is the coefficient of linear transformation for the 1th channel;</p>
<p>b1 is the offset of linear transformation for the 1th channel;</p>
<p>a2 is the coefficient of linear transformation for the 2th channel;</p>
<p>b2 is the offset of linear transformation for the 2th channel;</p>
</div></blockquote>
</li>
</ul>
<p><strong>Returns:</strong></p>
<p>Return 0 on success and other values on failure.</p>
</section>
<section id="pushimage">
<h2><span class="section-number">5.17.3.5. </span>PushImage<a class="headerlink" href="#pushimage" title="Link to this heading"></a></h2>
<p>push image data</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">PushImage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">channel_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">image_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">image</span><span class="p">:</span> <span class="n">BMImage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Parameters:</strong>
* channel_idx: int</p>
<p>The channel index of the input image</p>
<ul class="simple">
<li><p>image_idx: int</p></li>
</ul>
<p>The image index of the input image</p>
<ul class="simple">
<li><p>image: BMImage</p></li>
</ul>
<p>The input image</p>
<p><strong>Returns:</strong></p>
<p>Return 0 on success and other values on failure.</p>
</section>
<section id="getbatchdata-npy">
<h2><span class="section-number">5.17.3.6. </span>GetBatchData_Npy<a class="headerlink" href="#getbatchdata-npy" title="Link to this heading"></a></h2>
<p>Get a batch of inference results. When using this interface, use_mat_output must be False because the result type is BMImage.</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">GetBatchData_Npy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">BMImage</span><span class="p">],</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span><span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]]</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Returns:</strong></p>
<p>tuple[output_array, ost_images, channels, image_idxs, padding_attrs]</p>
<ul class="simple">
<li><p>output_array: dict[str, ndarray]</p></li>
</ul>
<p>The inference result</p>
<ul class="simple">
<li><p>ost_images: list[BMImage]</p></li>
</ul>
<p>Original image queue</p>
<ul class="simple">
<li><p>channels: list[int]</p></li>
</ul>
<p>The result corresponds to the channel sequence of the original picture.</p>
<ul class="simple">
<li><p>image_idxs: list[int]</p></li>
</ul>
<p>The result corresponds to the index sequence of the original picture.</p>
<ul class="simple">
<li><p>padding_attrs: list[list[int]]</p></li>
</ul>
<p>The attribute list of the filling image. The starting point coordinate x, starting point coordinate y, the width after scaling, and the height after scaling.</p>
</section>
<section id="getbatchdata-npy2">
<h2><span class="section-number">5.17.3.7. </span>GetBatchData_Npy2<a class="headerlink" href="#getbatchdata-npy2" title="Link to this heading"></a></h2>
<p>Get a batch of inference results. When using this interface, use_mat_output must be True because the result type is numpy.ndarray[numpy.uint8].</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">GetBatchData_Npy2</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">uint8</span><span class="p">]],</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span><span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Returns:</strong></p>
<p>tuple[output_array, ost_images, channels, image_idxs, padding_attrs]</p>
<ul class="simple">
<li><p>output_array: dict[str, ndarray]</p></li>
</ul>
<p>The inference result</p>
<ul class="simple">
<li><p>ost_images: list[numpy.ndarray[numpy.uint8]]</p></li>
</ul>
<p>Original image queue</p>
<ul class="simple">
<li><p>channels: list[int]</p></li>
</ul>
<p>The result corresponds to the channel sequence of the original picture.</p>
<ul class="simple">
<li><p>image_idxs: list[int]</p></li>
</ul>
<p>The result corresponds to the index sequence of the original picture.</p>
<ul class="simple">
<li><p>padding_attrs: list[list[int]]</p></li>
</ul>
<p>The attribute list of the filling image. The starting point coordinate x, starting point coordinate y, the width after scaling, and the height after scaling.</p>
</section>
<section id="getbatchdata">
<h2><span class="section-number">5.17.3.8. </span>GetBatchData<a class="headerlink" href="#getbatchdata" title="Link to this heading"></a></h2>
<p>Get a batch of inference results. When using this interface, use_mat_output must be False because the result type is BMImage. It is worth noting that output tensors must be manually released.</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">GetBatchData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">need_d2s</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">TensorPTRWithName</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">BMImage</span><span class="p">],</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span><span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p>need_d2s: bool</p></li>
</ul>
<p>Whether to move data to the system memory. The default value is True, which means Yes.</p>
<p><strong>Returns:</strong></p>
<p>tuple[output_array, ost_images, channels, image_idxs, padding_attrs]</p>
<ul class="simple">
<li><p>output_array: list[TensorPTRWithName]</p></li>
</ul>
<p>The inference result</p>
<ul class="simple">
<li><p>ost_images: list[BMImage]</p></li>
</ul>
<p>Original image queue</p>
<ul class="simple">
<li><p>channels: list[int]</p></li>
</ul>
<p>The result corresponds to the channel sequence of the original picture.</p>
<ul class="simple">
<li><p>image_idxs: list[int]</p></li>
</ul>
<p>The result corresponds to the index sequence of the original picture.</p>
<ul class="simple">
<li><p>padding_attrs: list[list[int]]</p></li>
</ul>
<p>The attribute list of the filling image. The starting point coordinate x, starting point coordinate y, the width after scaling, and the height after scaling.</p>
</section>
<section id="get-graph-name">
<h2><span class="section-number">5.17.3.9. </span>get_graph_name<a class="headerlink" href="#get-graph-name" title="Link to this heading"></a></h2>
<p>Get the name of model computation graph</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_graph_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Returns:</strong></p>
<p>Return the first name of model computation graph</p>
</section>
<section id="get-input-width">
<h2><span class="section-number">5.17.3.10. </span>get_input_width<a class="headerlink" href="#get-input-width" title="Link to this heading"></a></h2>
<p>Get the width of model input.</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_width</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Returns:</strong></p>
<p>Return the width of model input.</p>
</section>
<section id="get-input-height">
<h2><span class="section-number">5.17.3.11. </span>get_input_height<a class="headerlink" href="#get-input-height" title="Link to this heading"></a></h2>
<p>Get the height of model input.</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_height</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Returns:</strong></p>
<p>Return the height of model input.</p>
</section>
<section id="get-output-names">
<h2><span class="section-number">5.17.3.12. </span>get_output_names<a class="headerlink" href="#get-output-names" title="Link to this heading"></a></h2>
<p>Get tensor names of model output.</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Returns:</strong></p>
<p>Return all tensor names of model output.</p>
</section>
<section id="get-output-shape">
<h2><span class="section-number">5.17.3.13. </span>get_output_shape<a class="headerlink" href="#get-output-shape" title="Link to this heading"></a></h2>
<p>Get the shape of the specified output Tensor</p>
<dl>
<dt><strong>Interface:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p>tensor_name: str</p></li>
</ul>
<p>The name of output tensor</p>
<p><strong>Returns:</strong></p>
<p>Return the shape of the specified output Tensor</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sail.ImagePreProcess.html" class="btn btn-neutral float-left" title="5.17.2. sail.ImagePreProcess" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="sail.algo_yolov5_post_1output.html" class="btn btn-neutral float-right" title="5.17.4.1. sail.algo_yolov5_post_1output" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, SOPHGO.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>