

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>5.6. sail.EngineLLM &mdash; SOPHON-SAIL 3.10.2
 文档</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=9080cc91"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="5.7. sail.BMImage" href="sail.BMImage.html" />
    <link rel="prev" title="5.5. sail.Engine" href="sail.Engine.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            SOPHON-SAIL
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">目录</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../1_disclaimer.html">1. 声明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_sail.html">2. SAIL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3_build.html">3. 编译安装指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_module_cpp.html">4. SAIL C++ API 参考</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../5_module_python.html">5. SAIL Python API 参考</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Basicfunction.html">5.1. Basic function</a></li>
<li class="toctree-l2"><a class="reference internal" href="0_enum_type/enum_index.html">5.2. SAIL 枚举类型</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.Handle.html">5.3. sail.Handle</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.Tensor.html">5.4. sail.Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.Engine.html">5.5. sail.Engine</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">5.6. sail.EngineLLM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">5.6.1. 通用参数说明</a></li>
<li class="toctree-l3"><a class="reference internal" href="#init">5.6.2. 构造函数 __init__</a></li>
<li class="toctree-l3"><a class="reference internal" href="#process">5.6.3. 推理接口 process</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">5.6.4. 获取信息接口</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#get-device-ids">5.6.4.1. get_device_ids</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-graph-names">5.6.4.2. get_graph_names</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-addr-mode">5.6.4.3. get_addr_mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-stage-num">5.6.4.4. get_stage_num</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-num">5.6.4.5. get_input_num</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-num">5.6.4.6. get_output_num</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-is-dynamic">5.6.4.7. get_is_dynamic</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-name">5.6.4.8. get_input_name</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-name">5.6.4.9. get_output_name</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-tensor-devid">5.6.4.10. get_input_tensor_devid</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-tensor-devid">5.6.4.11. get_output_tensor_devid</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-shape">5.6.4.12. get_input_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-shape">5.6.4.13. get_output_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-max-shape">5.6.4.14. get_input_max_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-max-shape">5.6.4.15. get_output_max_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-dtype">5.6.4.16. get_input_dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-dtype">5.6.4.17. get_output_dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-scale">5.6.4.18. get_input_scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-scale">5.6.4.19. get_output_scale</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tensor">5.6.5. 创建Tensor接口</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#get-input-tensors">5.6.5.1. get_input_tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-tensor">5.6.5.2. get_input_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-tensors">5.6.5.3. get_output_tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-tensor">5.6.5.4. get_output_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-input-tensors-addrmode0">5.6.5.5. get_input_tensors_addrmode0</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-output-tensors-addrmode0">5.6.5.6. get_output_tensors_addrmode0</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sail.BMImage.html">5.7. sail.BMImage</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.Bmcv.html">5.8. sail.Bmcv</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.Decoder.html">5.9. sail.Decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.MultiDecoder.html">5.10. sail.MultiDecoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.Encoder.html">5.11. sail.Encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.PaddingAtrr.html">5.12. sail.PaddingAtrr</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.Blend.html">5.13. sail.Blend</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.Decoder_RawStream.html">5.14. sail.Decoder_RawStream</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.BMImageArray.html">5.15. sail.BMImageArray</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.bm_image.html">5.16. sail.bm_image</a></li>
<li class="toctree-l2"><a class="reference internal" href="sail.MultiEngine.html">5.17. sail.MultiEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_high_perform_interface/high_perform_index.html">5.18. SAIL Python 高性能接口</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../6_appendix.html">6. 附录</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SOPHON-SAIL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../5_module_python.html"><span class="section-number">5. </span>SAIL Python API 参考</a></li>
      <li class="breadcrumb-item active"><span class="section-number">5.6. </span>sail.EngineLLM</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/module_python/sail.EngineLLM.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sail-enginellm">
<h1><span class="section-number">5.6. </span>sail.EngineLLM<a class="headerlink" href="#sail-enginellm" title="Link to this heading"></a></h1>
<p>EngineLLM针对大语言模型推理而设计，可以实现多芯bmodel的加载与管理。</p>
<section id="id1">
<h2><span class="section-number">5.6.1. </span>通用参数说明<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<ul>
<li><p><strong>graph_name</strong>: str</p>
<p>需要获取信息的计算图的名称</p>
</li>
<li><p><strong>tensor_name</strong>: str</p>
<p>需要获取信息的Tensor（张量）的名称</p>
</li>
<li><p><strong>index</strong>: int</p>
<p>Tensor的索引</p>
</li>
<li><p><strong>stage</strong>: int</p>
<p>stage的索引</p>
</li>
</ul>
</section>
<section id="init">
<h2><span class="section-number">5.6.2. </span>构造函数 __init__<a class="headerlink" href="#init" title="Link to this heading"></a></h2>
<p>EngineLLM构造函数，初始化EngineLLM实例。</p>
<p><strong>接口形式1:</strong></p>
<p>创建EngineLLM实例，从bmodel文件中加载模型。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bmodel_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>参数说明1:</strong></p>
<ul class="simple">
<li><p>bmodel_path: str</p></li>
</ul>
<p>bmodel文件的路径</p>
<ul class="simple">
<li><p>dev_ids: list[int]</p></li>
</ul>
<p>EngineLLM实例使用的智能视觉深度学习处理器的id列表</p>
<p><strong>接口形式2:</strong></p>
<p>创建EngineLLM实例，从内存数据中加载模型。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bmodel_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">,</span> <span class="n">bmodel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>参数说明2:</strong></p>
<ul class="simple">
<li><p>bmodel_bytes: bytes</p></li>
</ul>
<p>bmodel在系统内存中的bytes</p>
<ul class="simple">
<li><p>bmodel_size: int</p></li>
</ul>
<p>bmodel在内存中的字节数</p>
<ul class="simple">
<li><p>dev_ids: list[int]</p></li>
</ul>
<p>EngineLLM实例使用的智能视觉深度学习处理器的id列表</p>
<p><strong>接口形式3:</strong></p>
<p>创建EngineLLM实例，从bmodel文件中加载模型，加载时使用指定的bmruntime flag。
典型使用场景是，在BM1688设备上执行LLM模型的推理时，可以设置flag为 <code class="docutils literal notranslate"><span class="pre">BM_RUNTIME_SHARE_MEM</span></code> ，以节省设备内存。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bmodel_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">flags</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>参数说明1:</strong></p>
<ul class="simple">
<li><p>bmodel_path: str</p></li>
</ul>
<p>bmodel文件的路径</p>
<ul class="simple">
<li><p>flags: int</p></li>
</ul>
<p>加载bmodel使用的bmruntime flag。
推荐通过 <code class="docutils literal notranslate"><span class="pre">BmrtFlag</span></code> 枚举设置，例如 <code class="docutils literal notranslate"><span class="pre">sail.BmrtFlag.BM_RUNTIME_SHARE_MEM</span></code> 。
更多信息请参考《BMRuntime 开发参考手册》。</p>
<ul class="simple">
<li><p>dev_ids: list[int]</p></li>
</ul>
<p>EngineLLM实例使用的智能视觉深度学习处理器的id列表</p>
<dl>
<dt><strong>示例代码:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sophon.sail</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sail</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">bmodel_path</span> <span class="o">=</span> <span class="s2">&quot;example_8dev.bmodel&quot;</span>
    <span class="n">dev_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span>

    <span class="n">engine1</span> <span class="o">=</span> <span class="n">sail</span><span class="o">.</span><span class="n">EngineLLM</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">)</span>

    <span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">,</span><span class="s2">&quot;rb&quot;</span><span class="p">)</span>
    <span class="n">datas</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">file_size</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">)</span>
    <span class="n">engine2</span> <span class="o">=</span> <span class="n">sail</span><span class="o">.</span><span class="n">EngineLLM</span><span class="p">(</span><span class="n">datas</span><span class="p">,</span> <span class="n">file_size</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">)</span>

    <span class="n">llm_bmodel_path</span> <span class="o">=</span> <span class="s2">&quot;llama.bmodel&quot;</span>
    <span class="n">flag</span> <span class="o">=</span> <span class="n">sail</span><span class="o">.</span><span class="n">BmrtFlag</span><span class="o">.</span><span class="n">BM_RUNTIME_SHARE_MEM</span>
    <span class="n">engine3</span> <span class="o">=</span> <span class="n">sail</span><span class="o">.</span><span class="n">EngineLLM</span><span class="p">(</span><span class="n">llm_bmodel_path</span><span class="p">,</span> <span class="n">flag</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="process">
<h2><span class="section-number">5.6.3. </span>推理接口 process<a class="headerlink" href="#process" title="Link to this heading"></a></h2>
<p>使用给定的输入输出Tensor，在某一个计算图上执行推理。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="nb">input</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
            <span class="n">output</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">])</span>
            <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>参数说明:</strong></p>
<ul class="simple">
<li><p>graph_name: str</p></li>
</ul>
<p>需要推理的计算图名称</p>
<ul class="simple">
<li><p>input: dict[int, Tensor]</p></li>
</ul>
<p>输入Tensor</p>
<ul class="simple">
<li><p>output: dict[int, Tensor]</p></li>
</ul>
<p>输出Tensor</p>
<p><strong>返回值说明:</strong></p>
<ul class="simple">
<li><p>return: int</p></li>
</ul>
<p>返回0表示推理成功，其他值表示失败</p>
<dl>
<dt><strong>示例代码:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sophon.sail</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sail</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">bmodel_path</span> <span class="o">=</span> <span class="s2">&quot;example_8dev.bmodel&quot;</span>
    <span class="n">dev_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span>

    <span class="n">engine1</span> <span class="o">=</span> <span class="n">sail</span><span class="o">.</span><span class="n">EngineLLM</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">)</span>
    <span class="n">graph_name_0</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_graph_names</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">input_tensors</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_input_tensors</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">)</span>
    <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_output_tensors</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">)</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">,</span> <span class="n">input_tensors</span><span class="p">,</span> <span class="n">output_tensors</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">ret</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">graph_name_0</span><span class="si">}</span><span class="s2"> inference failed!&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">graph_name_0</span><span class="si">}</span><span class="s2"> inference succeeded!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="id2">
<h2><span class="section-number">5.6.4. </span>获取信息接口<a class="headerlink" href="#id2" title="Link to this heading"></a></h2>
<p>此小节介绍的接口用于从EngineLLM实例中获取模型信息。</p>
<p>小节末尾提供了调用这些接口的例程。</p>
<section id="get-device-ids">
<h3><span class="section-number">5.6.4.1. </span>get_device_ids<a class="headerlink" href="#get-device-ids" title="Link to this heading"></a></h3>
<p>获取EngineLLM所使用的设备号列表。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_device_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>返回值说明:</strong></p>
<ul class="simple">
<li><p>dev_ids: list[int]</p></li>
</ul>
<p>返回EngineLLM所使用的设备号列表</p>
</section>
<section id="get-graph-names">
<h3><span class="section-number">5.6.4.2. </span>get_graph_names<a class="headerlink" href="#get-graph-names" title="Link to this heading"></a></h3>
<p>获取EngineLLM中所有载入的计算图（graph）的名称。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_graph_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
<p><strong>返回值说明:</strong></p>
<ul class="simple">
<li><p>graph_names: list[str]</p></li>
</ul>
<p>获取EngineLLM中所有计算图的名称</p>
</section>
<section id="get-addr-mode">
<h3><span class="section-number">5.6.4.3. </span>get_addr_mode<a class="headerlink" href="#get-addr-mode" title="Link to this heading"></a></h3>
<p>获取EngineLLM中某个指定计算图的addr_mode。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_addr_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-stage-num">
<h3><span class="section-number">5.6.4.4. </span>get_stage_num<a class="headerlink" href="#get-stage-num" title="Link to this heading"></a></h3>
<p>获取EngineLLM中某个指定计算图的stage_num。
stage_num的定义请参考《BMRuntime开发参考手册》。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_stage_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-input-num">
<h3><span class="section-number">5.6.4.5. </span>get_input_num<a class="headerlink" href="#get-input-num" title="Link to this heading"></a></h3>
<p>获取EngineLLM中某个指定计算图的输入的个数。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-output-num">
<h3><span class="section-number">5.6.4.6. </span>get_output_num<a class="headerlink" href="#get-output-num" title="Link to this heading"></a></h3>
<p>获取EngineLLM中某个指定计算图的输出的个数。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-is-dynamic">
<h3><span class="section-number">5.6.4.7. </span>get_is_dynamic<a class="headerlink" href="#get-is-dynamic" title="Link to this heading"></a></h3>
<p>获取EngineLLM中某个指定计算图是否是动态的。
动态网络的定义请参考《BMRuntime开发参考手册》。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_is_dynamic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-input-name">
<h3><span class="section-number">5.6.4.8. </span>get_input_name<a class="headerlink" href="#get-input-name" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输入Tensor名称。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-output-name">
<h3><span class="section-number">5.6.4.9. </span>get_output_name<a class="headerlink" href="#get-output-name" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输出Tensor名称。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-input-tensor-devid">
<h3><span class="section-number">5.6.4.10. </span>get_input_tensor_devid<a class="headerlink" href="#get-input-tensor-devid" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输入Tensor的设备ID。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_tensor_devid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-output-tensor-devid">
<h3><span class="section-number">5.6.4.11. </span>get_output_tensor_devid<a class="headerlink" href="#get-output-tensor-devid" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输出Tensor的设备ID。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_tensor_devid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-input-shape">
<h3><span class="section-number">5.6.4.12. </span>get_input_shape<a class="headerlink" href="#get-input-shape" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输入Tensor的形状。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-output-shape">
<h3><span class="section-number">5.6.4.13. </span>get_output_shape<a class="headerlink" href="#get-output-shape" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输出Tensor的形状。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-input-max-shape">
<h3><span class="section-number">5.6.4.14. </span>get_input_max_shape<a class="headerlink" href="#get-input-max-shape" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输入Tensor在不同stage中的最大形状。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_max_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-output-max-shape">
<h3><span class="section-number">5.6.4.15. </span>get_output_max_shape<a class="headerlink" href="#get-output-max-shape" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输出Tensor在不同stage中的最大形状。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_max_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-input-dtype">
<h3><span class="section-number">5.6.4.16. </span>get_input_dtype<a class="headerlink" href="#get-input-dtype" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输入Tensor的数据类型。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dtype</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-output-dtype">
<h3><span class="section-number">5.6.4.17. </span>get_output_dtype<a class="headerlink" href="#get-output-dtype" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输出Tensor的数据类型。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dtype</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-input-scale">
<h3><span class="section-number">5.6.4.18. </span>get_input_scale<a class="headerlink" href="#get-input-scale" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输入Tensor的缩放因子。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</pre></div>
</div>
</dd>
</dl>
</section>
<section id="get-output-scale">
<h3><span class="section-number">5.6.4.19. </span>get_output_scale<a class="headerlink" href="#get-output-scale" title="Link to this heading"></a></h3>
<p>获取指定计算图中某个索引的输出Tensor的缩放因子。</p>
<dl>
<dt><strong>接口形式:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</pre></div>
</div>
</dd>
<dt><strong>示例代码:</strong></dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sophon.sail</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sail</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">bmodel_path</span> <span class="o">=</span> <span class="s2">&quot;example_8dev.bmodel&quot;</span>
    <span class="n">dev_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)]</span>
    <span class="n">engine1</span> <span class="o">=</span> <span class="n">sail</span><span class="o">.</span><span class="n">EngineLLM</span><span class="p">(</span><span class="n">bmodel_path</span><span class="p">,</span> <span class="n">dev_ids</span><span class="p">)</span>
    <span class="n">dev_ids</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_device_ids</span><span class="p">()</span>
    <span class="n">graph_names</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_graph_names</span><span class="p">()</span>
    <span class="n">graph_name_0</span> <span class="o">=</span> <span class="n">graph_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">query_index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">query_stage</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">addr_mode</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_addr_mode</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">)</span>
    <span class="n">stage_num</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_stage_num</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">)</span>
    <span class="n">input_num</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_input_num</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">)</span>
    <span class="n">is_dynamic</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_is_dynamic</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">)</span>
    <span class="n">input_name</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_input_name</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">,</span> <span class="n">query_index</span><span class="p">)</span>
    <span class="n">input_tensor_devid</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_input_tensor_devid</span><span class="p">(</span>
                                <span class="n">graph_name_0</span><span class="p">,</span> <span class="n">query_index</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_input_shape</span><span class="p">(</span>
                                    <span class="n">graph_name_0</span><span class="p">,</span> <span class="n">query_index</span><span class="p">,</span> <span class="n">query_stage</span><span class="p">)</span>
    <span class="n">input_max_shape</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_input_max_shape</span><span class="p">(</span>
                            <span class="n">graph_name_0</span><span class="p">,</span> <span class="n">query_index</span><span class="p">)</span>
    <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_input_dtype</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">,</span> <span class="n">query_index</span><span class="p">)</span>
    <span class="n">input_scale</span> <span class="o">=</span> <span class="n">engine1</span><span class="o">.</span><span class="n">get_input_scale</span><span class="p">(</span><span class="n">graph_name_0</span><span class="p">,</span> <span class="n">query_index</span><span class="p">)</span>
    <span class="c1"># usage about output is omitted, which is the same as input</span>
</pre></div>
</div>
</dd>
</dl>
</section>
</section>
<section id="tensor">
<h2><span class="section-number">5.6.5. </span>创建Tensor接口<a class="headerlink" href="#tensor" title="Link to this heading"></a></h2>
<section id="get-input-tensors">
<h3><span class="section-number">5.6.5.1. </span>get_input_tensors<a class="headerlink" href="#get-input-tensors" title="Link to this heading"></a></h3>
<p>获取指定计算图中符合条件的输入Tensor及其索引。</p>
<p>该接口使用net_info中的input_mems创建Tensor，而非额外重新申请内存。
为了内存安全，该接口仅在addr_mode模式为1时可用，否则返回的字典为空。
input_mems和addr_mode的定义请参考《BMRuntime开发参考手册》。</p>
<p><strong>接口形式1:</strong></p>
<p>根据Tensor名称和stage，获取一组对应的输入Tensor。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>接口形式2:</strong></p>
<p>根据stage，获取一组对应的输入Tensor。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>返回值说明:</strong></p>
<p>返回由索引和Tensor组成的字典dict[int, Tensor]</p>
</section>
<section id="get-input-tensor">
<h3><span class="section-number">5.6.5.2. </span>get_input_tensor<a class="headerlink" href="#get-input-tensor" title="Link to this heading"></a></h3>
<p>根据索引和stage，获取一个对应的输入Tensor。</p>
<p>该接口使用net_info中的input_mems创建Tensor，而非额外重新申请内存。
为了内存安全，该接口仅在addr_mode模式为1时可用，否则返回的字典为空。
input_mems和addr_mode的定义请参考《BMRuntime开发参考手册》。</p>
<p><strong>接口形式:</strong></p>
<p>根据Tensor名称和索引，获取一个对应的输入Tensor。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="get-output-tensors">
<h3><span class="section-number">5.6.5.3. </span>get_output_tensors<a class="headerlink" href="#get-output-tensors" title="Link to this heading"></a></h3>
<p>获取指定计算图中符合条件的输出Tensor及其索引。</p>
<p>该接口使用net_info中的output_mems创建Tensor，而非额外重新申请内存。
为了内存安全，该接口仅在addr_mode模式为1时可用，否则返回的字典为空。
output_mems和addr_mode的定义请参考《BMRuntime开发参考手册》。</p>
<p><strong>接口形式1:</strong></p>
<p>根据Tensor名称和stage，获取一组对应的输出Tensor。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>接口形式2:</strong></p>
<p>根据stage，获取一组对应的输出Tensor。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>返回值说明:</strong></p>
<p>返回由索引和Tensor组成的字典dict[int, Tensor]</p>
</section>
<section id="get-output-tensor">
<h3><span class="section-number">5.6.5.4. </span>get_output_tensor<a class="headerlink" href="#get-output-tensor" title="Link to this heading"></a></h3>
<p>根据索引和stage，获取一个对应的输出Tensor。</p>
<p>该接口使用net_info中的output_mems创建Tensor，而非额外重新申请内存。
为了内存安全，该接口仅在addr_mode模式为1时可用，否则返回的字典为空。
output_mems和addr_mode的定义请参考《BMRuntime开发参考手册》。</p>
<p><strong>接口形式:</strong></p>
<p>根据Tensor名称和索引，获取一个对应的输出Tensor。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="get-input-tensors-addrmode0">
<h3><span class="section-number">5.6.5.5. </span>get_input_tensors_addrmode0<a class="headerlink" href="#get-input-tensors-addrmode0" title="Link to this heading"></a></h3>
<p>根据Tensor名称和stage，获取一组对应的输入Tensor。</p>
<p>该接口使用net_info中的input_mems创建Tensor，而非额外重新申请内存。
该接口在addr_mode模式不为1时也可用，调用者需要确认Tensor的内存安全。
addr_mode的定义请参考《BMRuntime开发参考手册》。</p>
<p><strong>接口形式:</strong></p>
<p>获取所有输入Tensors。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_input_tensors_addrmode0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>返回值说明:</strong></p>
<p>返回由索引和Tensor组成的字典dict[int, Tensor]</p>
</section>
<section id="get-output-tensors-addrmode0">
<h3><span class="section-number">5.6.5.6. </span>get_output_tensors_addrmode0<a class="headerlink" href="#get-output-tensors-addrmode0" title="Link to this heading"></a></h3>
<p>根据Tensor名称和stage，获取一组对应的输出Tensor。</p>
<p>该接口使用net_info中的output_mems创建Tensor，而非额外重新申请内存。
该接口在addr_mode模式不为1时也可用，调用者需要确认Tensor的内存安全。
addr_mode的定义请参考《BMRuntime开发参考手册》。</p>
<p><strong>接口形式:</strong></p>
<p>获取所有输出Tensors。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_output_tensors_addrmode0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>返回值说明:</strong></p>
<p>返回由索引和Tensor组成的字典dict[int, Tensor]</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="页脚">
        <a href="sail.Engine.html" class="btn btn-neutral float-left" title="5.5. sail.Engine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="sail.BMImage.html" class="btn btn-neutral float-right" title="5.7. sail.BMImage" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, SOPHGO。</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>